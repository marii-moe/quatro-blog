<!DOCTYPE html>
<html xmlns="http://www.w3.org/1999/xhtml" lang="en" xml:lang="en"><head>

<meta charset="utf-8">
<meta name="generator" content="quarto-1.0.35">

<meta name="viewport" content="width=device-width, initial-scale=1.0, user-scalable=yes">

<meta name="author" content="marii">

<title>blog - FP16</title>
<style>
code{white-space: pre-wrap;}
span.smallcaps{font-variant: small-caps;}
span.underline{text-decoration: underline;}
div.column{display: inline-block; vertical-align: top; width: 50%;}
div.hanging-indent{margin-left: 1.5em; text-indent: -1.5em;}
ul.task-list{list-style: none;}
pre > code.sourceCode { white-space: pre; position: relative; }
pre > code.sourceCode > span { display: inline-block; line-height: 1.25; }
pre > code.sourceCode > span:empty { height: 1.2em; }
.sourceCode { overflow: visible; }
code.sourceCode > span { color: inherit; text-decoration: inherit; }
div.sourceCode { margin: 1em 0; }
pre.sourceCode { margin: 0; }
@media screen {
div.sourceCode { overflow: auto; }
}
@media print {
pre > code.sourceCode { white-space: pre-wrap; }
pre > code.sourceCode > span { text-indent: -5em; padding-left: 5em; }
}
pre.numberSource code
  { counter-reset: source-line 0; }
pre.numberSource code > span
  { position: relative; left: -4em; counter-increment: source-line; }
pre.numberSource code > span > a:first-child::before
  { content: counter(source-line);
    position: relative; left: -1em; text-align: right; vertical-align: baseline;
    border: none; display: inline-block;
    -webkit-touch-callout: none; -webkit-user-select: none;
    -khtml-user-select: none; -moz-user-select: none;
    -ms-user-select: none; user-select: none;
    padding: 0 4px; width: 4em;
    color: #aaaaaa;
  }
pre.numberSource { margin-left: 3em; border-left: 1px solid #aaaaaa;  padding-left: 4px; }
div.sourceCode
  {   }
@media screen {
pre > code.sourceCode > span > a:first-child::before { text-decoration: underline; }
}
code span.al { color: #ff0000; font-weight: bold; } /* Alert */
code span.an { color: #60a0b0; font-weight: bold; font-style: italic; } /* Annotation */
code span.at { color: #7d9029; } /* Attribute */
code span.bn { color: #40a070; } /* BaseN */
code span.bu { } /* BuiltIn */
code span.cf { color: #007020; font-weight: bold; } /* ControlFlow */
code span.ch { color: #4070a0; } /* Char */
code span.cn { color: #880000; } /* Constant */
code span.co { color: #60a0b0; font-style: italic; } /* Comment */
code span.cv { color: #60a0b0; font-weight: bold; font-style: italic; } /* CommentVar */
code span.do { color: #ba2121; font-style: italic; } /* Documentation */
code span.dt { color: #902000; } /* DataType */
code span.dv { color: #40a070; } /* DecVal */
code span.er { color: #ff0000; font-weight: bold; } /* Error */
code span.ex { } /* Extension */
code span.fl { color: #40a070; } /* Float */
code span.fu { color: #06287e; } /* Function */
code span.im { } /* Import */
code span.in { color: #60a0b0; font-weight: bold; font-style: italic; } /* Information */
code span.kw { color: #007020; font-weight: bold; } /* Keyword */
code span.op { color: #666666; } /* Operator */
code span.ot { color: #007020; } /* Other */
code span.pp { color: #bc7a00; } /* Preprocessor */
code span.sc { color: #4070a0; } /* SpecialChar */
code span.ss { color: #bb6688; } /* SpecialString */
code span.st { color: #4070a0; } /* String */
code span.va { color: #19177c; } /* Variable */
code span.vs { color: #4070a0; } /* VerbatimString */
code span.wa { color: #60a0b0; font-weight: bold; font-style: italic; } /* Warning */
</style>


<script src="../../site_libs/quarto-nav/quarto-nav.js"></script>
<script src="../../site_libs/quarto-nav/headroom.min.js"></script>
<script src="../../site_libs/clipboard/clipboard.min.js"></script>
<script src="../../site_libs/quarto-search/autocomplete.umd.js"></script>
<script src="../../site_libs/quarto-search/fuse.min.js"></script>
<script src="../../site_libs/quarto-search/quarto-search.js"></script>
<meta name="quarto:offset" content="../../">
<script src="../../site_libs/quarto-html/quarto.js"></script>
<script src="../../site_libs/quarto-html/popper.min.js"></script>
<script src="../../site_libs/quarto-html/tippy.umd.min.js"></script>
<script src="../../site_libs/quarto-html/anchor.min.js"></script>
<link href="../../site_libs/quarto-html/tippy.css" rel="stylesheet">
<link href="../../site_libs/quarto-html/quarto-syntax-highlighting.css" rel="stylesheet" id="quarto-text-highlighting-styles">
<script src="../../site_libs/bootstrap/bootstrap.min.js"></script>
<link href="../../site_libs/bootstrap/bootstrap-icons.css" rel="stylesheet">
<link href="../../site_libs/bootstrap/bootstrap.min.css" rel="stylesheet" id="quarto-bootstrap" data-mode="light">
<script id="quarto-search-options" type="application/json">{
  "location": "navbar",
  "copy-button": false,
  "collapse-after": 3,
  "panel-placement": "end",
  "type": "overlay",
  "limit": 20,
  "language": {
    "search-no-results-text": "No results",
    "search-matching-documents-text": "matching documents",
    "search-copy-link-title": "Copy link to search",
    "search-hide-matches-text": "Hide additional matches",
    "search-more-match-text": "more match in this document",
    "search-more-matches-text": "more matches in this document",
    "search-clear-button-title": "Clear",
    "search-detached-cancel-button-title": "Cancel",
    "search-submit-button-title": "Submit"
  }
}</script>
<script src="https://cdnjs.cloudflare.com/ajax/libs/require.js/2.3.6/require.min.js" integrity="sha512-c3Nl8+7g4LMSTdrm621y7kf9v3SDPnhxLNhcjFJbKECVnmZHTdo+IRO05sNLTH/D3vA6u1X32ehoLC7WFVdheg==" crossorigin="anonymous"></script>
<script src="https://cdnjs.cloudflare.com/ajax/libs/jquery/3.5.1/jquery.min.js" integrity="sha512-bLT0Qm9VnAYZDflyKcBaQ2gg0hSYNQrJ8RilYldYQ1FxQYoCLtUjuuRuZo+fjqhx/qtq/1itJ0C2ejDxltZVFg==" crossorigin="anonymous"></script>
<script type="application/javascript">define('jquery', [],function() {return window.jQuery;})</script>


<link rel="stylesheet" href="../../styles.css">
</head>

<body class="nav-fixed fullcontent">

<div id="quarto-search-results"></div>
  <header id="quarto-header" class="headroom fixed-top">
    <nav class="navbar navbar-expand-lg navbar-dark ">
      <div class="navbar-container container-fluid">
      <a class="navbar-brand" href="../../index.html">
    <span class="navbar-title">blog</span>
  </a>
          <button class="navbar-toggler" type="button" data-bs-toggle="collapse" data-bs-target="#navbarCollapse" aria-controls="navbarCollapse" aria-expanded="false" aria-label="Toggle navigation" onclick="if (window.quartoToggleHeadroom) { window.quartoToggleHeadroom(); }">
  <span class="navbar-toggler-icon"></span>
</button>
          <div class="collapse navbar-collapse" id="navbarCollapse">
            <ul class="navbar-nav navbar-nav-scroll ms-auto">
  <li class="nav-item">
    <a class="nav-link" href="../../about.html">About</a>
  </li>  
  <li class="nav-item compact">
    <a class="nav-link" href="https://github.com/"><i class="bi bi-github" role="img">
</i> 
 </a>
  </li>  
  <li class="nav-item compact">
    <a class="nav-link" href="https://twitter.com"><i class="bi bi-twitter" role="img">
</i> 
 </a>
  </li>  
</ul>
              <div id="quarto-search" class="" title="Search"></div>
          </div> <!-- /navcollapse -->
      </div> <!-- /container-fluid -->
    </nav>
</header>
<!-- content -->
<header id="title-block-header" class="quarto-title-block default page-columns page-full">
  <div class="quarto-title-banner page-columns page-full">
    <div class="quarto-title column-body">
      <h1 class="title">FP16</h1>
                      </div>
  </div>
    
  
  <div class="quarto-title-meta">

      <div>
      <div class="quarto-title-meta-heading">Author</div>
      <div class="quarto-title-meta-contents">
               <p>marii </p>
            </div>
    </div>
      
      
    </div>
    
  
  </header><div id="quarto-content" class="quarto-container page-columns page-rows-contents page-layout-article page-navbar">
<!-- sidebar -->
<!-- margin-sidebar -->
    
<!-- main -->
<main class="content quarto-banner-title-block" id="quarto-document-content">




<p>We are going to take a look at how mixed precision or fp16 training works.</p>
<section id="getting-setup" class="level3">
<h3 class="anchored" data-anchor-id="getting-setup">Getting setup</h3>
<p>Lets start by looking at our data. We are working with low resolution cifar images.</p>
<div class="cell" data-execution_count="3">
<div class="sourceCode cell-code" id="cb1"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb1-1"><a href="#cb1-1" aria-hidden="true" tabindex="-1"></a>bs<span class="op">=</span><span class="dv">128</span></span>
<span id="cb1-2"><a href="#cb1-2" aria-hidden="true" tabindex="-1"></a>dls<span class="op">=</span>DataBlock((ImageBlock(),</span>
<span id="cb1-3"><a href="#cb1-3" aria-hidden="true" tabindex="-1"></a>               CategoryBlock()),</span>
<span id="cb1-4"><a href="#cb1-4" aria-hidden="true" tabindex="-1"></a>          item_tfms<span class="op">=</span>[Resize(<span class="dv">32</span>)],</span>
<span id="cb1-5"><a href="#cb1-5" aria-hidden="true" tabindex="-1"></a>          batch_tfms<span class="op">=</span>(Normalize.from_stats(<span class="op">*</span>cifar_stats)),</span>
<span id="cb1-6"><a href="#cb1-6" aria-hidden="true" tabindex="-1"></a>          get_items<span class="op">=</span>get_image_files,</span>
<span id="cb1-7"><a href="#cb1-7" aria-hidden="true" tabindex="-1"></a>          get_y<span class="op">=</span>parent_label</span>
<span id="cb1-8"><a href="#cb1-8" aria-hidden="true" tabindex="-1"></a>).dataloaders(path,bs<span class="op">=</span>bs,val_bs<span class="op">=</span><span class="dv">2</span><span class="op">*</span>bs)</span>
<span id="cb1-9"><a href="#cb1-9" aria-hidden="true" tabindex="-1"></a>dls.show_batch()</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-display">
<p><img src="FP16_files/figure-html/cell-4-output-1.png" class="img-fluid"></p>
</div>
</div>
<p>We create a function to recreate our dataloader, because we will be doing it a lot for repeatability.</p>
<div class="cell" data-execution_count="4">
<div class="sourceCode cell-code" id="cb2"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb2-1"><a href="#cb2-1" aria-hidden="true" tabindex="-1"></a><span class="kw">def</span> create_dls():</span>
<span id="cb2-2"><a href="#cb2-2" aria-hidden="true" tabindex="-1"></a>    bs<span class="op">=</span><span class="dv">128</span></span>
<span id="cb2-3"><a href="#cb2-3" aria-hidden="true" tabindex="-1"></a>    <span class="cf">return</span> DataBlock((ImageBlock(),</span>
<span id="cb2-4"><a href="#cb2-4" aria-hidden="true" tabindex="-1"></a>                   CategoryBlock()),</span>
<span id="cb2-5"><a href="#cb2-5" aria-hidden="true" tabindex="-1"></a>              item_tfms<span class="op">=</span>[Resize(<span class="dv">32</span>)],</span>
<span id="cb2-6"><a href="#cb2-6" aria-hidden="true" tabindex="-1"></a>              batch_tfms<span class="op">=</span>(Normalize.from_stats(<span class="op">*</span>cifar_stats)),</span>
<span id="cb2-7"><a href="#cb2-7" aria-hidden="true" tabindex="-1"></a>              get_items<span class="op">=</span>get_image_files,</span>
<span id="cb2-8"><a href="#cb2-8" aria-hidden="true" tabindex="-1"></a>              get_y<span class="op">=</span>parent_label</span>
<span id="cb2-9"><a href="#cb2-9" aria-hidden="true" tabindex="-1"></a>    ).dataloaders(path,bs<span class="op">=</span>bs,val_bs<span class="op">=</span><span class="dv">2</span><span class="op">*</span>bs)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</div>
<p>We will just use a simple resnet to test our work.</p>
<div class="cell" data-execution_count="5">
<div class="sourceCode cell-code" id="cb3"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb3-1"><a href="#cb3-1" aria-hidden="true" tabindex="-1"></a>learn<span class="op">=</span>Learner(dls,resnet18(),opt_func<span class="op">=</span>SGD)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</div>
<p>We can make a tensor fp16 by calling <code>Tensor.half()</code></p>
<div class="cell" data-execution_count="6">
<div class="sourceCode cell-code" id="cb4"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb4-1"><a href="#cb4-1" aria-hidden="true" tabindex="-1"></a>torch.tensor(<span class="fl">5.</span>),torch.tensor(<span class="fl">5.</span>).half()</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-display" data-execution_count="6">
<pre><code>(tensor(5.), tensor(5., dtype=torch.float16))</code></pre>
</div>
</div>
</section>
<section id="whole-model-half-precision" class="level3">
<h3 class="anchored" data-anchor-id="whole-model-half-precision">Whole model half precision</h3>
<p>We start by training our whole model using half precision. This includes converting our input data and out parameters to fp16.</p>
<div class="cell" data-execution_count="7">
<div class="sourceCode cell-code" id="cb6"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb6-1"><a href="#cb6-1" aria-hidden="true" tabindex="-1"></a><span class="kw">class</span> fp16Callback(Callback):</span>
<span id="cb6-2"><a href="#cb6-2" aria-hidden="true" tabindex="-1"></a>    <span class="kw">def</span> before_batch(<span class="va">self</span>):</span>
<span id="cb6-3"><a href="#cb6-3" aria-hidden="true" tabindex="-1"></a>        <span class="va">self</span>.learn.xb<span class="op">=</span>(<span class="va">self</span>.xb[<span class="dv">0</span>].half(),)</span>
<span id="cb6-4"><a href="#cb6-4" aria-hidden="true" tabindex="-1"></a>        <span class="va">self</span>.learn.model<span class="op">=</span><span class="va">self</span>.model.half()</span>
<span id="cb6-5"><a href="#cb6-5" aria-hidden="true" tabindex="-1"></a>    <span class="kw">def</span> after_batch(<span class="va">self</span>):</span>
<span id="cb6-6"><a href="#cb6-6" aria-hidden="true" tabindex="-1"></a>        <span class="co">#fix loss for logging</span></span>
<span id="cb6-7"><a href="#cb6-7" aria-hidden="true" tabindex="-1"></a>        <span class="va">self</span>.learn.loss<span class="op">=</span><span class="va">self</span>.learn.loss.<span class="bu">float</span>()</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</div>
<div class="cell" data-execution_count="8">
<div class="sourceCode cell-code" id="cb7"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb7-1"><a href="#cb7-1" aria-hidden="true" tabindex="-1"></a><span class="cf">with</span> less_random():</span>
<span id="cb7-2"><a href="#cb7-2" aria-hidden="true" tabindex="-1"></a>    dls<span class="op">=</span>create_dls()</span>
<span id="cb7-3"><a href="#cb7-3" aria-hidden="true" tabindex="-1"></a>    learn<span class="op">=</span>Learner(dls,resnet18(),opt_func<span class="op">=</span>SGD,cbs<span class="op">=</span>[fp16Callback])</span>
<span id="cb7-4"><a href="#cb7-4" aria-hidden="true" tabindex="-1"></a>    learn.fit(<span class="dv">6</span>)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-display">

<style>
    /* Turns off some styling */
    progress {
        /* gets rid of default border in Firefox and Opera. */
        border: none;
        /* Needs to be in here for Safari polyfill so background images work as expected. */
        background-size: auto;
    }
    progress:not([value]), progress:not([value])::-webkit-progress-bar {
        background: repeating-linear-gradient(45deg, #7e7e7e, #7e7e7e 10px, #5c5c5c 10px, #5c5c5c 20px);
    }
    .progress-bar-interrupted, .progress-bar-interrupted::-webkit-progress-bar {
        background: #F44336;
    }
</style>
</div>
<div class="cell-output cell-output-display">

<table class="dataframe table table-sm table-striped">
  <thead>
    <tr>
      <th>epoch</th>
      <th>train_loss</th>
      <th>valid_loss</th>
      <th>time</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <td>0</td>
      <td>2.154748</td>
      <td>2.054516</td>
      <td>00:17</td>
    </tr>
    <tr>
      <td>1</td>
      <td>1.803467</td>
      <td>1.779198</td>
      <td>00:15</td>
    </tr>
    <tr>
      <td>2</td>
      <td>1.646736</td>
      <td>1.664151</td>
      <td>00:15</td>
    </tr>
    <tr>
      <td>3</td>
      <td>1.547711</td>
      <td>1.596234</td>
      <td>00:15</td>
    </tr>
    <tr>
      <td>4</td>
      <td>1.487926</td>
      <td>1.549276</td>
      <td>00:15</td>
    </tr>
    <tr>
      <td>5</td>
      <td>1.433233</td>
      <td>1.512745</td>
      <td>00:15</td>
    </tr>
  </tbody>
</table>
</div>
</div>
<p>How does this compare to training with fp32?</p>
<div class="cell" data-execution_count="9">
<div class="sourceCode cell-code" id="cb8"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb8-1"><a href="#cb8-1" aria-hidden="true" tabindex="-1"></a><span class="cf">with</span> less_random():</span>
<span id="cb8-2"><a href="#cb8-2" aria-hidden="true" tabindex="-1"></a>    dls<span class="op">=</span>create_dls()</span>
<span id="cb8-3"><a href="#cb8-3" aria-hidden="true" tabindex="-1"></a>    learn<span class="op">=</span>Learner(dls,resnet18(),opt_func<span class="op">=</span>SGD)</span>
<span id="cb8-4"><a href="#cb8-4" aria-hidden="true" tabindex="-1"></a>    learn.fit(<span class="dv">6</span>)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-display">

<style>
    /* Turns off some styling */
    progress {
        /* gets rid of default border in Firefox and Opera. */
        border: none;
        /* Needs to be in here for Safari polyfill so background images work as expected. */
        background-size: auto;
    }
    progress:not([value]), progress:not([value])::-webkit-progress-bar {
        background: repeating-linear-gradient(45deg, #7e7e7e, #7e7e7e 10px, #5c5c5c 10px, #5c5c5c 20px);
    }
    .progress-bar-interrupted, .progress-bar-interrupted::-webkit-progress-bar {
        background: #F44336;
    }
</style>
</div>
<div class="cell-output cell-output-display">

<table class="dataframe table table-sm table-striped">
  <thead>
    <tr>
      <th>epoch</th>
      <th>train_loss</th>
      <th>valid_loss</th>
      <th>time</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <td>0</td>
      <td>2.084821</td>
      <td>1.969784</td>
      <td>00:15</td>
    </tr>
    <tr>
      <td>1</td>
      <td>1.742251</td>
      <td>1.712177</td>
      <td>00:14</td>
    </tr>
    <tr>
      <td>2</td>
      <td>1.575977</td>
      <td>1.596902</td>
      <td>00:14</td>
    </tr>
    <tr>
      <td>3</td>
      <td>1.465374</td>
      <td>1.527497</td>
      <td>00:14</td>
    </tr>
    <tr>
      <td>4</td>
      <td>1.398808</td>
      <td>1.475065</td>
      <td>00:15</td>
    </tr>
    <tr>
      <td>5</td>
      <td>1.337400</td>
      <td>1.437802</td>
      <td>00:14</td>
    </tr>
  </tbody>
</table>
</div>
</div>
<p>Seems we are doing a bit worse…</p>
</section>
<section id="looking-at-the-gradients." class="level3">
<h3 class="anchored" data-anchor-id="looking-at-the-gradients.">Looking at the gradients.</h3>
<p>We create a callback that collects the data needed to create a colorful deminsion graph of our gradients.</p>
<div class="cell" data-execution_count="11">
<div class="sourceCode cell-code" id="cb9"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb9-1"><a href="#cb9-1" aria-hidden="true" tabindex="-1"></a><span class="at">@patch</span></span>
<span id="cb9-2"><a href="#cb9-2" aria-hidden="true" tabindex="-1"></a><span class="kw">def</span> after_backward(<span class="va">self</span>:GradLogCallback):</span>
<span id="cb9-3"><a href="#cb9-3" aria-hidden="true" tabindex="-1"></a>    <span class="cf">for</span> n,p <span class="kw">in</span> learn.model.named_parameters():</span>
<span id="cb9-4"><a href="#cb9-4" aria-hidden="true" tabindex="-1"></a>        <span class="cf">if</span> p.numel()<span class="op">&gt;</span><span class="dv">10</span>: </span>
<span id="cb9-5"><a href="#cb9-5" aria-hidden="true" tabindex="-1"></a>            <span class="cf">if</span> n <span class="kw">not</span> <span class="kw">in</span> <span class="va">self</span>.log: <span class="va">self</span>.log[n]<span class="op">=</span>[]</span>
<span id="cb9-6"><a href="#cb9-6" aria-hidden="true" tabindex="-1"></a>            <span class="va">self</span>.log[n]<span class="op">+=</span>[p.cpu().<span class="bu">abs</span>().<span class="bu">float</span>().histc(<span class="dv">100</span>,<span class="dv">0</span>,<span class="dv">1</span>)]</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</div>
<div class="cell" data-execution_count="12">
<div class="sourceCode cell-code" id="cb10"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb10-1"><a href="#cb10-1" aria-hidden="true" tabindex="-1"></a><span class="cf">with</span> less_random():</span>
<span id="cb10-2"><a href="#cb10-2" aria-hidden="true" tabindex="-1"></a>    dls<span class="op">=</span>create_dls()</span>
<span id="cb10-3"><a href="#cb10-3" aria-hidden="true" tabindex="-1"></a>    learn<span class="op">=</span>Learner(dls,resnet18(),opt_func<span class="op">=</span>SGD,cbs<span class="op">=</span>[fp16Callback,GradLogCallback])</span>
<span id="cb10-4"><a href="#cb10-4" aria-hidden="true" tabindex="-1"></a>    learn.fit(<span class="dv">6</span>)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-display">

<style>
    /* Turns off some styling */
    progress {
        /* gets rid of default border in Firefox and Opera. */
        border: none;
        /* Needs to be in here for Safari polyfill so background images work as expected. */
        background-size: auto;
    }
    progress:not([value]), progress:not([value])::-webkit-progress-bar {
        background: repeating-linear-gradient(45deg, #7e7e7e, #7e7e7e 10px, #5c5c5c 10px, #5c5c5c 20px);
    }
    .progress-bar-interrupted, .progress-bar-interrupted::-webkit-progress-bar {
        background: #F44336;
    }
</style>
</div>
<div class="cell-output cell-output-display">

<table class="dataframe table table-sm table-striped">
  <thead>
    <tr>
      <th>epoch</th>
      <th>train_loss</th>
      <th>valid_loss</th>
      <th>time</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <td>0</td>
      <td>2.154748</td>
      <td>2.054516</td>
      <td>00:25</td>
    </tr>
    <tr>
      <td>1</td>
      <td>1.803467</td>
      <td>1.779198</td>
      <td>00:25</td>
    </tr>
    <tr>
      <td>2</td>
      <td>1.646736</td>
      <td>1.664151</td>
      <td>00:25</td>
    </tr>
    <tr>
      <td>3</td>
      <td>1.547711</td>
      <td>1.596234</td>
      <td>00:25</td>
    </tr>
    <tr>
      <td>4</td>
      <td>1.487926</td>
      <td>1.549276</td>
      <td>00:25</td>
    </tr>
    <tr>
      <td>5</td>
      <td>1.433233</td>
      <td>1.512745</td>
      <td>00:25</td>
    </tr>
  </tbody>
</table>
</div>
</div>
<p>Most of the gradients are very close to zero. Just something to take note of, as the gradients don’t have a standard deviation of 1 like the activations.</p>
<div class="cell" data-execution_count="16">
<div class="sourceCode cell-code" id="cb11"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb11-1"><a href="#cb11-1" aria-hidden="true" tabindex="-1"></a>show_colorful_grid(learn.cbs[<span class="op">-</span><span class="dv">1</span>].log)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-display">
<p><img src="FP16_files/figure-html/cell-15-output-1.png" class="img-fluid"></p>
</div>
</div>
<div class="cell" data-execution_count="17">
<div class="sourceCode cell-code" id="cb12"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb12-1"><a href="#cb12-1" aria-hidden="true" tabindex="-1"></a><span class="cf">with</span> less_random():</span>
<span id="cb12-2"><a href="#cb12-2" aria-hidden="true" tabindex="-1"></a>    dls<span class="op">=</span>create_dls()</span>
<span id="cb12-3"><a href="#cb12-3" aria-hidden="true" tabindex="-1"></a>    learn<span class="op">=</span>Learner(dls,resnet18(),opt_func<span class="op">=</span>SGD,cbs<span class="op">=</span>[GradLogCallback])</span>
<span id="cb12-4"><a href="#cb12-4" aria-hidden="true" tabindex="-1"></a>    learn.fit(<span class="dv">6</span>)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-display">

<style>
    /* Turns off some styling */
    progress {
        /* gets rid of default border in Firefox and Opera. */
        border: none;
        /* Needs to be in here for Safari polyfill so background images work as expected. */
        background-size: auto;
    }
    progress:not([value]), progress:not([value])::-webkit-progress-bar {
        background: repeating-linear-gradient(45deg, #7e7e7e, #7e7e7e 10px, #5c5c5c 10px, #5c5c5c 20px);
    }
    .progress-bar-interrupted, .progress-bar-interrupted::-webkit-progress-bar {
        background: #F44336;
    }
</style>
</div>
<div class="cell-output cell-output-display">

<table class="dataframe table table-sm table-striped">
  <thead>
    <tr>
      <th>epoch</th>
      <th>train_loss</th>
      <th>valid_loss</th>
      <th>time</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <td>0</td>
      <td>2.084821</td>
      <td>1.969784</td>
      <td>00:27</td>
    </tr>
    <tr>
      <td>1</td>
      <td>1.742251</td>
      <td>1.712177</td>
      <td>00:27</td>
    </tr>
    <tr>
      <td>2</td>
      <td>1.575977</td>
      <td>1.596902</td>
      <td>00:27</td>
    </tr>
    <tr>
      <td>3</td>
      <td>1.465374</td>
      <td>1.527497</td>
      <td>00:26</td>
    </tr>
    <tr>
      <td>4</td>
      <td>1.398808</td>
      <td>1.475065</td>
      <td>00:26</td>
    </tr>
    <tr>
      <td>5</td>
      <td>1.337400</td>
      <td>1.437802</td>
      <td>00:27</td>
    </tr>
  </tbody>
</table>
</div>
</div>
<p>The fp32 gradients actually look fairly similar.</p>
<div class="cell" data-execution_count="19">
<div class="sourceCode cell-code" id="cb13"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb13-1"><a href="#cb13-1" aria-hidden="true" tabindex="-1"></a>show_colorful_grid(learn.cbs[<span class="op">-</span><span class="dv">1</span>].log)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-display">
<p><img src="FP16_files/figure-html/cell-17-output-1.png" class="img-fluid"></p>
</div>
</div>
</section>
<section id="looking-near-0-for-the-gradients" class="level3">
<h3 class="anchored" data-anchor-id="looking-near-0-for-the-gradients">Looking near 0 for the Gradients</h3>
<p>We look from 0 to 3 times the standard deviation of the first batch to get a closer look at the gradients</p>
<div class="cell" data-execution_count="20">
<div class="sourceCode cell-code" id="cb14"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb14-1"><a href="#cb14-1" aria-hidden="true" tabindex="-1"></a><span class="at">@patch</span></span>
<span id="cb14-2"><a href="#cb14-2" aria-hidden="true" tabindex="-1"></a><span class="kw">def</span> after_backward(<span class="va">self</span>:GradLogCallback):</span>
<span id="cb14-3"><a href="#cb14-3" aria-hidden="true" tabindex="-1"></a>    <span class="cf">for</span> n,p <span class="kw">in</span> learn.model.named_parameters():</span>
<span id="cb14-4"><a href="#cb14-4" aria-hidden="true" tabindex="-1"></a>        <span class="cf">if</span> p.numel()<span class="op">&gt;</span><span class="dv">10</span>: </span>
<span id="cb14-5"><a href="#cb14-5" aria-hidden="true" tabindex="-1"></a>            <span class="cf">if</span> n <span class="kw">not</span> <span class="kw">in</span> <span class="va">self</span>.log: <span class="va">self</span>.log[n]<span class="op">=</span>[<span class="dv">3</span><span class="op">*</span>p.cpu().<span class="bu">abs</span>().<span class="bu">float</span>().std()]</span>
<span id="cb14-6"><a href="#cb14-6" aria-hidden="true" tabindex="-1"></a>            <span class="va">self</span>.log[n]<span class="op">+=</span>[p.cpu().<span class="bu">abs</span>().<span class="bu">float</span>().histc(<span class="dv">100</span>,<span class="dv">0</span>,<span class="va">self</span>.log[n][<span class="dv">0</span>].item())]</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</div>
<div class="cell" data-execution_count="21">
<div class="sourceCode cell-code" id="cb15"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb15-1"><a href="#cb15-1" aria-hidden="true" tabindex="-1"></a><span class="cf">with</span> less_random():</span>
<span id="cb15-2"><a href="#cb15-2" aria-hidden="true" tabindex="-1"></a>    dls<span class="op">=</span>create_dls()</span>
<span id="cb15-3"><a href="#cb15-3" aria-hidden="true" tabindex="-1"></a>    learn<span class="op">=</span>Learner(dls,resnet18(),opt_func<span class="op">=</span>SGD,cbs<span class="op">=</span>[fp16Callback,GradLogCallback])</span>
<span id="cb15-4"><a href="#cb15-4" aria-hidden="true" tabindex="-1"></a>    learn.fit(<span class="dv">6</span>)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-display">

<style>
    /* Turns off some styling */
    progress {
        /* gets rid of default border in Firefox and Opera. */
        border: none;
        /* Needs to be in here for Safari polyfill so background images work as expected. */
        background-size: auto;
    }
    progress:not([value]), progress:not([value])::-webkit-progress-bar {
        background: repeating-linear-gradient(45deg, #7e7e7e, #7e7e7e 10px, #5c5c5c 10px, #5c5c5c 20px);
    }
    .progress-bar-interrupted, .progress-bar-interrupted::-webkit-progress-bar {
        background: #F44336;
    }
</style>
</div>
<div class="cell-output cell-output-display">

<table class="dataframe table table-sm table-striped">
  <thead>
    <tr>
      <th>epoch</th>
      <th>train_loss</th>
      <th>valid_loss</th>
      <th>time</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <td>0</td>
      <td>2.154748</td>
      <td>2.054516</td>
      <td>00:30</td>
    </tr>
    <tr>
      <td>1</td>
      <td>1.803467</td>
      <td>1.779198</td>
      <td>00:29</td>
    </tr>
    <tr>
      <td>2</td>
      <td>1.646736</td>
      <td>1.664151</td>
      <td>00:29</td>
    </tr>
    <tr>
      <td>3</td>
      <td>1.547711</td>
      <td>1.596234</td>
      <td>00:30</td>
    </tr>
    <tr>
      <td>4</td>
      <td>1.487926</td>
      <td>1.549276</td>
      <td>00:29</td>
    </tr>
    <tr>
      <td>5</td>
      <td>1.433233</td>
      <td>1.512745</td>
      <td>00:30</td>
    </tr>
  </tbody>
</table>
</div>
</div>
<div class="cell" data-execution_count="22">
<div class="sourceCode cell-code" id="cb16"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb16-1"><a href="#cb16-1" aria-hidden="true" tabindex="-1"></a>fp16_log<span class="op">=</span>learn.grad_log.log</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</div>
<p>We can see something now! Pay a little bit of attention to the <code>bn.weight</code> graphs.</p>
<div class="cell" data-execution_count="23">
<div class="sourceCode cell-code" id="cb17"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb17-1"><a href="#cb17-1" aria-hidden="true" tabindex="-1"></a>show_colorful_grid(learn.cbs[<span class="op">-</span><span class="dv">1</span>].log)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-display">
<p><img src="FP16_files/figure-html/cell-21-output-1.png" class="img-fluid"></p>
</div>
</div>
<div class="cell" data-execution_count="24">
<div class="sourceCode cell-code" id="cb18"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb18-1"><a href="#cb18-1" aria-hidden="true" tabindex="-1"></a><span class="cf">with</span> less_random():</span>
<span id="cb18-2"><a href="#cb18-2" aria-hidden="true" tabindex="-1"></a>    dls<span class="op">=</span>create_dls()</span>
<span id="cb18-3"><a href="#cb18-3" aria-hidden="true" tabindex="-1"></a>    learn<span class="op">=</span>Learner(dls,resnet18(),opt_func<span class="op">=</span>SGD,cbs<span class="op">=</span>[GradLogCallback])</span>
<span id="cb18-4"><a href="#cb18-4" aria-hidden="true" tabindex="-1"></a>    learn.fit(<span class="dv">6</span>)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-display">

<style>
    /* Turns off some styling */
    progress {
        /* gets rid of default border in Firefox and Opera. */
        border: none;
        /* Needs to be in here for Safari polyfill so background images work as expected. */
        background-size: auto;
    }
    progress:not([value]), progress:not([value])::-webkit-progress-bar {
        background: repeating-linear-gradient(45deg, #7e7e7e, #7e7e7e 10px, #5c5c5c 10px, #5c5c5c 20px);
    }
    .progress-bar-interrupted, .progress-bar-interrupted::-webkit-progress-bar {
        background: #F44336;
    }
</style>
</div>
<div class="cell-output cell-output-display">

<table class="dataframe table table-sm table-striped">
  <thead>
    <tr>
      <th>epoch</th>
      <th>train_loss</th>
      <th>valid_loss</th>
      <th>time</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <td>0</td>
      <td>2.084821</td>
      <td>1.969784</td>
      <td>00:29</td>
    </tr>
    <tr>
      <td>1</td>
      <td>1.742251</td>
      <td>1.712177</td>
      <td>00:32</td>
    </tr>
    <tr>
      <td>2</td>
      <td>1.575977</td>
      <td>1.596902</td>
      <td>00:32</td>
    </tr>
    <tr>
      <td>3</td>
      <td>1.465374</td>
      <td>1.527497</td>
      <td>00:31</td>
    </tr>
    <tr>
      <td>4</td>
      <td>1.398808</td>
      <td>1.475065</td>
      <td>00:32</td>
    </tr>
    <tr>
      <td>5</td>
      <td>1.337400</td>
      <td>1.437802</td>
      <td>00:32</td>
    </tr>
  </tbody>
</table>
</div>
</div>
<p>hm, these FP32 gradients mostly look the same, though we are not getting a horizontal line for the batchnorm weights.</p>
<div class="cell" data-execution_count="25">
<div class="sourceCode cell-code" id="cb19"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb19-1"><a href="#cb19-1" aria-hidden="true" tabindex="-1"></a>show_colorful_grid(learn.cbs[<span class="op">-</span><span class="dv">1</span>].log)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-display">
<p><img src="FP16_files/figure-html/cell-23-output-1.png" class="img-fluid"></p>
</div>
</div>
<div class="cell" data-execution_count="26">
<div class="sourceCode cell-code" id="cb20"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb20-1"><a href="#cb20-1" aria-hidden="true" tabindex="-1"></a>fp32_log<span class="op">=</span>learn.grad_log.log</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</div>
<p>One thing to note is that the minimum positive value for fp16 is a not as small as fp32.</p>
<div class="cell" data-execution_count="27">
<div class="sourceCode cell-code" id="cb21"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb21-1"><a href="#cb21-1" aria-hidden="true" tabindex="-1"></a>torch.tensor(<span class="dv">2</span><span class="op">**-</span><span class="dv">24</span>,dtype<span class="op">=</span>torch.half),torch.tensor(<span class="dv">2</span><span class="op">**-</span><span class="dv">149</span>)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-display" data-execution_count="27">
<pre><code>(tensor(5.9605e-08, dtype=torch.float16), tensor(1.4013e-45))</code></pre>
</div>
</div>
<p>hm, the batchnorm weight gradients standard deviations are <strong>ZERO</strong> for fp16!</p>
<div class="cell" data-execution_count="28">
<div class="sourceCode cell-code" id="cb23"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb23-1"><a href="#cb23-1" aria-hidden="true" tabindex="-1"></a>[[k,fp16_log[k][<span class="dv">0</span>].item(),fp32_log[k][<span class="dv">0</span>].item()] <span class="cf">for</span> k <span class="kw">in</span> fp16_log <span class="cf">if</span> <span class="st">'bn'</span> <span class="kw">in</span> k]</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-display" data-execution_count="28">
<pre><code>[['bn1.weight', 0.0, 0.0060293180868029594],
 ['bn1.bias', 0.004148084670305252, 0.003580566728487611],
 ['layer1.0.bn1.weight', 0.0, 0.005399828776717186],
 ['layer1.0.bn1.bias', 0.004158522468060255, 0.0034905048087239265],
 ['layer1.0.bn2.weight', 0.0, 0.004458598792552948],
 ['layer1.0.bn2.bias', 0.0027511364314705133, 0.0024442975409328938],
 ['layer1.1.bn1.weight', 0.0, 0.0039586215279996395],
 ['layer1.1.bn1.bias', 0.002898486563935876, 0.002269925782456994],
 ['layer1.1.bn2.weight', 0.0, 0.0035925875417888165],
 ['layer1.1.bn2.bias', 0.001713279401883483, 0.0014464608393609524],
 ['layer2.0.bn1.weight', 0.0, 0.003240257501602173],
 ['layer2.0.bn1.bias', 0.0017084497958421707, 0.0014696172438561916],
 ['layer2.0.bn2.weight', 0.0, 0.002757459646090865],
 ['layer2.0.bn2.bias', 0.0018845133017748594, 0.0017825027462095022],
 ['layer2.1.bn1.weight', 0.0, 0.0026580658741295338],
 ['layer2.1.bn1.bias', 0.0015702887903898954, 0.0015195324085652828],
 ['layer2.1.bn2.weight', 0.0, 0.002109265886247158],
 ['layer2.1.bn2.bias', 0.0011786026880145073, 0.001151321455836296],
 ['layer3.0.bn1.weight', 0.0, 0.001799717196263373],
 ['layer3.0.bn1.bias', 0.0011105844751000404, 0.000998087227344513],
 ['layer3.0.bn2.weight', 0.0, 0.0017275793943554163],
 ['layer3.0.bn2.bias', 0.001101263682357967, 0.0009456288535147905],
 ['layer3.1.bn1.weight', 0.0, 0.001411611563526094],
 ['layer3.1.bn1.bias', 0.0008357313927263021, 0.0007302637677639723],
 ['layer3.1.bn2.weight', 0.0, 0.0011884564300999045],
 ['layer3.1.bn2.bias', 0.0006777657545171678, 0.0004925086977891624],
 ['layer4.0.bn1.weight', 0.0, 0.0009125272044911981],
 ['layer4.0.bn1.bias', 0.0005735242739319801, 0.0004978459910489619],
 ['layer4.0.bn2.weight', 0.0, 0.0017549480544403195],
 ['layer4.0.bn2.bias', 0.002376189222559333, 0.002254981081932783],
 ['layer4.1.bn1.weight', 0.0, 0.0008248933590948582],
 ['layer4.1.bn1.bias', 0.0006004928727634251, 0.0004860978224314749],
 ['layer4.1.bn2.weight', 0.0, 0.00195809337310493],
 ['layer4.1.bn2.bias', 0.0034636915661394596, 0.003284711856395006]]</code></pre>
</div>
</div>
</section>
<section id="letting-batchnorm-stay-in-fp32" class="level3">
<h3 class="anchored" data-anchor-id="letting-batchnorm-stay-in-fp32">Letting Batchnorm stay in FP32</h3>
<p>We create a function here that just allows us to apply a funtion to both our module, and one of its parameters.</p>
<div class="cell" data-execution_count="29">
<div class="sourceCode cell-code" id="cb25"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb25-1"><a href="#cb25-1" aria-hidden="true" tabindex="-1"></a><span class="kw">def</span> apply_p(f,m):</span>
<span id="cb25-2"><a href="#cb25-2" aria-hidden="true" tabindex="-1"></a>    <span class="cf">for</span> module <span class="kw">in</span> m.children():</span>
<span id="cb25-3"><a href="#cb25-3" aria-hidden="true" tabindex="-1"></a>        apply_p(f,module)</span>
<span id="cb25-4"><a href="#cb25-4" aria-hidden="true" tabindex="-1"></a>        <span class="cf">for</span> n,p <span class="kw">in</span> module.named_parameters(recurse<span class="op">=</span><span class="va">False</span>):</span>
<span id="cb25-5"><a href="#cb25-5" aria-hidden="true" tabindex="-1"></a>            f(module,n)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</div>
<p>Here we allow BatchNorm weights to stay in fp32.</p>
<div class="cell" data-execution_count="30">
<div class="sourceCode cell-code" id="cb26"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb26-1"><a href="#cb26-1" aria-hidden="true" tabindex="-1"></a><span class="kw">class</span> fp16Callback(Callback):</span>
<span id="cb26-2"><a href="#cb26-2" aria-hidden="true" tabindex="-1"></a>    <span class="kw">def</span> before_fit(<span class="va">self</span>):</span>
<span id="cb26-3"><a href="#cb26-3" aria-hidden="true" tabindex="-1"></a>        <span class="kw">def</span> f(m,n):</span>
<span id="cb26-4"><a href="#cb26-4" aria-hidden="true" tabindex="-1"></a>            <span class="bu">getattr</span>(m,n).data<span class="op">=</span><span class="bu">getattr</span>(m,n).data.<span class="bu">float</span>() <span class="cf">if</span> <span class="bu">isinstance</span>(m,nn.BatchNorm2d) <span class="cf">else</span> <span class="bu">getattr</span>(m,n).data.half()</span>
<span id="cb26-5"><a href="#cb26-5" aria-hidden="true" tabindex="-1"></a>        apply_p(f,<span class="va">self</span>.learn.model)</span>
<span id="cb26-6"><a href="#cb26-6" aria-hidden="true" tabindex="-1"></a>    <span class="kw">def</span> before_batch(<span class="va">self</span>):</span>
<span id="cb26-7"><a href="#cb26-7" aria-hidden="true" tabindex="-1"></a>        <span class="va">self</span>.learn.xb<span class="op">=</span>(<span class="va">self</span>.xb[<span class="dv">0</span>].half(),)</span>
<span id="cb26-8"><a href="#cb26-8" aria-hidden="true" tabindex="-1"></a>    <span class="kw">def</span> after_pred(<span class="va">self</span>):</span>
<span id="cb26-9"><a href="#cb26-9" aria-hidden="true" tabindex="-1"></a>        <span class="co">#loss should be calculated in fp32 as well</span></span>
<span id="cb26-10"><a href="#cb26-10" aria-hidden="true" tabindex="-1"></a>        <span class="va">self</span>.learn.pred<span class="op">=</span><span class="va">self</span>.learn.pred.<span class="bu">float</span>()</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</div>
<div class="cell" data-execution_count="31">
<div class="sourceCode cell-code" id="cb27"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb27-1"><a href="#cb27-1" aria-hidden="true" tabindex="-1"></a><span class="cf">with</span> less_random():</span>
<span id="cb27-2"><a href="#cb27-2" aria-hidden="true" tabindex="-1"></a>    dls<span class="op">=</span>create_dls()</span>
<span id="cb27-3"><a href="#cb27-3" aria-hidden="true" tabindex="-1"></a>    learn<span class="op">=</span>Learner(dls,resnet18(),opt_func<span class="op">=</span>SGD,cbs<span class="op">=</span>[fp16Callback,GradLogCallback])</span>
<span id="cb27-4"><a href="#cb27-4" aria-hidden="true" tabindex="-1"></a>    learn.fit(<span class="dv">6</span>)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-display">

<style>
    /* Turns off some styling */
    progress {
        /* gets rid of default border in Firefox and Opera. */
        border: none;
        /* Needs to be in here for Safari polyfill so background images work as expected. */
        background-size: auto;
    }
    progress:not([value]), progress:not([value])::-webkit-progress-bar {
        background: repeating-linear-gradient(45deg, #7e7e7e, #7e7e7e 10px, #5c5c5c 10px, #5c5c5c 20px);
    }
    .progress-bar-interrupted, .progress-bar-interrupted::-webkit-progress-bar {
        background: #F44336;
    }
</style>
</div>
<div class="cell-output cell-output-display">

<table class="dataframe table table-sm table-striped">
  <thead>
    <tr>
      <th>epoch</th>
      <th>train_loss</th>
      <th>valid_loss</th>
      <th>time</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <td>0</td>
      <td>2.160702</td>
      <td>2.038649</td>
      <td>00:29</td>
    </tr>
    <tr>
      <td>1</td>
      <td>1.807114</td>
      <td>1.770107</td>
      <td>00:29</td>
    </tr>
    <tr>
      <td>2</td>
      <td>1.642703</td>
      <td>1.656874</td>
      <td>00:28</td>
    </tr>
    <tr>
      <td>3</td>
      <td>1.542962</td>
      <td>1.592482</td>
      <td>00:29</td>
    </tr>
    <tr>
      <td>4</td>
      <td>1.486021</td>
      <td>1.546489</td>
      <td>00:29</td>
    </tr>
    <tr>
      <td>5</td>
      <td>1.425706</td>
      <td>1.504864</td>
      <td>00:29</td>
    </tr>
  </tbody>
</table>
</div>
</div>
<p>hmm, we have slightly better results, but nothing too close to our fp32 model.</p>
<div class="cell" data-execution_count="32">
<div class="sourceCode cell-code" id="cb28"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb28-1"><a href="#cb28-1" aria-hidden="true" tabindex="-1"></a>fp16_bn_log<span class="op">=</span>learn.grad_log.log</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</div>
<p>Though, we have gotten the bn weights to have gradients!</p>
<div class="cell" data-execution_count="33">
<div class="sourceCode cell-code" id="cb29"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb29-1"><a href="#cb29-1" aria-hidden="true" tabindex="-1"></a>[[k,fp16_log[k][<span class="dv">0</span>].item(),fp16_bn_log[k][<span class="dv">0</span>].item(),fp32_log[k][<span class="dv">0</span>].item()] <span class="cf">for</span> k <span class="kw">in</span> fp16_log <span class="cf">if</span> <span class="st">'bn'</span> <span class="kw">in</span> k]</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-display" data-execution_count="33">
<pre><code>[['bn1.weight', 0.0, 0.006746089085936546, 0.0060293180868029594],
 ['bn1.bias',
  0.004148084670305252,
  0.003786720335483551,
  0.003580566728487611],
 ['layer1.0.bn1.weight', 0.0, 0.005284080747514963, 0.005399828776717186],
 ['layer1.0.bn1.bias',
  0.004158522468060255,
  0.003640677547082305,
  0.0034905048087239265],
 ['layer1.0.bn2.weight', 0.0, 0.005027716979384422, 0.004458598792552948],
 ['layer1.0.bn2.bias',
  0.0027511364314705133,
  0.0025208923034369946,
  0.0024442975409328938],
 ['layer1.1.bn1.weight', 0.0, 0.00424396526068449, 0.0039586215279996395],
 ['layer1.1.bn1.bias',
  0.002898486563935876,
  0.002260061912238598,
  0.002269925782456994],
 ['layer1.1.bn2.weight', 0.0, 0.004007537383586168, 0.0035925875417888165],
 ['layer1.1.bn2.bias',
  0.001713279401883483,
  0.0016484896186739206,
  0.0014464608393609524],
 ['layer2.0.bn1.weight', 0.0, 0.0031620513182133436, 0.003240257501602173],
 ['layer2.0.bn1.bias',
  0.0017084497958421707,
  0.0016835747519508004,
  0.0014696172438561916],
 ['layer2.0.bn2.weight', 0.0, 0.0031509941909462214, 0.002757459646090865],
 ['layer2.0.bn2.bias',
  0.0018845133017748594,
  0.0020461969543248415,
  0.0017825027462095022],
 ['layer2.1.bn1.weight', 0.0, 0.003080494701862335, 0.0026580658741295338],
 ['layer2.1.bn1.bias',
  0.0015702887903898954,
  0.0016526294639334083,
  0.0015195324085652828],
 ['layer2.1.bn2.weight', 0.0, 0.0026030924636870623, 0.002109265886247158],
 ['layer2.1.bn2.bias',
  0.0011786026880145073,
  0.0013054630253463984,
  0.001151321455836296],
 ['layer3.0.bn1.weight', 0.0, 0.0020066993311047554, 0.001799717196263373],
 ['layer3.0.bn1.bias',
  0.0011105844751000404,
  0.0010541853262111545,
  0.000998087227344513],
 ['layer3.0.bn2.weight', 0.0, 0.0021246818359941244, 0.0017275793943554163],
 ['layer3.0.bn2.bias',
  0.001101263682357967,
  0.0010443663923069835,
  0.0009456288535147905],
 ['layer3.1.bn1.weight', 0.0, 0.001690064324066043, 0.001411611563526094],
 ['layer3.1.bn1.bias',
  0.0008357313927263021,
  0.0008858887013047934,
  0.0007302637677639723],
 ['layer3.1.bn2.weight', 0.0, 0.0014081220142543316, 0.0011884564300999045],
 ['layer3.1.bn2.bias',
  0.0006777657545171678,
  0.0006280804518610239,
  0.0004925086977891624],
 ['layer4.0.bn1.weight', 0.0, 0.0010809964733198285, 0.0009125272044911981],
 ['layer4.0.bn1.bias',
  0.0005735242739319801,
  0.0005982829607091844,
  0.0004978459910489619],
 ['layer4.0.bn2.weight', 0.0, 0.0018873803783208132, 0.0017549480544403195],
 ['layer4.0.bn2.bias',
  0.002376189222559333,
  0.0023989235050976276,
  0.002254981081932783],
 ['layer4.1.bn1.weight', 0.0, 0.0010339637519791722, 0.0008248933590948582],
 ['layer4.1.bn1.bias',
  0.0006004928727634251,
  0.0006056932033970952,
  0.0004860978224314749],
 ['layer4.1.bn2.weight', 0.0, 0.002108693355694413, 0.00195809337310493],
 ['layer4.1.bn2.bias',
  0.0034636915661394596,
  0.0034976028837263584,
  0.003284711856395006]]</code></pre>
</div>
</div>
</section>
<section id="looking-at-the-gradients" class="level3">
<h3 class="anchored" data-anchor-id="looking-at-the-gradients">Looking at the gradients</h3>
<div class="quarto-figure quarto-figure-center">
<figure class="figure">
<p><img src="FP16_files/figure-html/nv_grads.png" class="img-fluid figure-img"></p>
<p></p><figcaption class="figure-caption">nv_grads.png</figcaption><p></p>
</figure>
</div>
<p>Image taken from here: https://docs.nvidia.com/deeplearning/performance/mixed-precision-training/index.html</p>
<p>Above we can see that some of the gradients will go to zero in fp16. This will happen more as the model trains and the gradients get smaller throughout training.</p>
<p>Here we are create seperate FP16 parameters for our model, while our optimizer uses the fp32 weights. We scale up the loss by <strong>128</strong> before our backwards pass, to increase the size of the gradients. We then descale it back <strong>128</strong> when converting back to fp32 for our optimizer step.</p>
<div class="cell" data-execution_count="34">
<div class="sourceCode cell-code" id="cb31"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb31-1"><a href="#cb31-1" aria-hidden="true" tabindex="-1"></a><span class="at">@patch</span></span>
<span id="cb31-2"><a href="#cb31-2" aria-hidden="true" tabindex="-1"></a><span class="kw">def</span> before_fit(<span class="va">self</span>:fp16Callback):</span>
<span id="cb31-3"><a href="#cb31-3" aria-hidden="true" tabindex="-1"></a>    <span class="va">self</span>.opt_params<span class="op">=</span> [p <span class="cf">for</span> p <span class="kw">in</span> <span class="va">self</span>.model.parameters()]</span>
<span id="cb31-4"><a href="#cb31-4" aria-hidden="true" tabindex="-1"></a>    <span class="kw">def</span> f(m,n):</span>
<span id="cb31-5"><a href="#cb31-5" aria-hidden="true" tabindex="-1"></a>        value<span class="op">=</span><span class="bu">getattr</span>(m,n).data.<span class="bu">float</span>() <span class="cf">if</span> <span class="bu">isinstance</span>(m,nn.BatchNorm2d) <span class="cf">else</span> <span class="bu">getattr</span>(m,n).data.half()</span>
<span id="cb31-6"><a href="#cb31-6" aria-hidden="true" tabindex="-1"></a>        <span class="bu">setattr</span>(m,n,nn.Parameter(value))</span>
<span id="cb31-7"><a href="#cb31-7" aria-hidden="true" tabindex="-1"></a>    apply_p(f,<span class="va">self</span>.learn.model)</span>
<span id="cb31-8"><a href="#cb31-8" aria-hidden="true" tabindex="-1"></a><span class="at">@patch</span></span>
<span id="cb31-9"><a href="#cb31-9" aria-hidden="true" tabindex="-1"></a><span class="kw">def</span> before_backward(<span class="va">self</span>:fp16Callback):</span>
<span id="cb31-10"><a href="#cb31-10" aria-hidden="true" tabindex="-1"></a>    <span class="va">self</span>.learn.loss_grad<span class="op">=</span><span class="dv">128</span><span class="op">*</span><span class="va">self</span>.learn.loss_grad</span>
<span id="cb31-11"><a href="#cb31-11" aria-hidden="true" tabindex="-1"></a><span class="at">@patch</span></span>
<span id="cb31-12"><a href="#cb31-12" aria-hidden="true" tabindex="-1"></a><span class="kw">def</span> after_backward(<span class="va">self</span>:fp16Callback):</span>
<span id="cb31-13"><a href="#cb31-13" aria-hidden="true" tabindex="-1"></a>    <span class="cf">for</span> mp,op <span class="kw">in</span> <span class="bu">zip</span>(<span class="va">self</span>.learn.model.parameters(),<span class="va">self</span>.opt_params):</span>
<span id="cb31-14"><a href="#cb31-14" aria-hidden="true" tabindex="-1"></a>        op.grad<span class="op">=</span>mp.grad.to(dtype<span class="op">=</span>torch.float32)<span class="op">/</span><span class="dv">128</span></span>
<span id="cb31-15"><a href="#cb31-15" aria-hidden="true" tabindex="-1"></a><span class="at">@patch</span></span>
<span id="cb31-16"><a href="#cb31-16" aria-hidden="true" tabindex="-1"></a><span class="kw">def</span> after_step(<span class="va">self</span>:fp16Callback):</span>
<span id="cb31-17"><a href="#cb31-17" aria-hidden="true" tabindex="-1"></a>    <span class="cf">for</span> mp,op <span class="kw">in</span> <span class="bu">zip</span>(<span class="va">self</span>.learn.model.parameters(),<span class="va">self</span>.opt_params):</span>
<span id="cb31-18"><a href="#cb31-18" aria-hidden="true" tabindex="-1"></a>        mp.data<span class="op">=</span> op.data.to(dtype<span class="op">=</span>torch.float16) <span class="cf">if</span>(op.grad.dtype<span class="op">!=</span>mp.grad.dtype) <span class="cf">else</span> op.data.clone()</span>
<span id="cb31-19"><a href="#cb31-19" aria-hidden="true" tabindex="-1"></a>    <span class="va">self</span>.learn.model.zero_grad()</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</div>
<div class="cell" data-execution_count="35">
<div class="sourceCode cell-code" id="cb32"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb32-1"><a href="#cb32-1" aria-hidden="true" tabindex="-1"></a><span class="cf">with</span> less_random():</span>
<span id="cb32-2"><a href="#cb32-2" aria-hidden="true" tabindex="-1"></a>    dls<span class="op">=</span>create_dls()</span>
<span id="cb32-3"><a href="#cb32-3" aria-hidden="true" tabindex="-1"></a>    learn<span class="op">=</span>Learner(dls,resnet18(),opt_func<span class="op">=</span>SGD,cbs<span class="op">=</span>[fp16Callback,GradLogCallback])</span>
<span id="cb32-4"><a href="#cb32-4" aria-hidden="true" tabindex="-1"></a>    learn.fit(<span class="dv">6</span>)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-display">

<style>
    /* Turns off some styling */
    progress {
        /* gets rid of default border in Firefox and Opera. */
        border: none;
        /* Needs to be in here for Safari polyfill so background images work as expected. */
        background-size: auto;
    }
    progress:not([value]), progress:not([value])::-webkit-progress-bar {
        background: repeating-linear-gradient(45deg, #7e7e7e, #7e7e7e 10px, #5c5c5c 10px, #5c5c5c 20px);
    }
    .progress-bar-interrupted, .progress-bar-interrupted::-webkit-progress-bar {
        background: #F44336;
    }
</style>
</div>
<div class="cell-output cell-output-display">

<table class="dataframe table table-sm table-striped">
  <thead>
    <tr>
      <th>epoch</th>
      <th>train_loss</th>
      <th>valid_loss</th>
      <th>time</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <td>0</td>
      <td>2.088479</td>
      <td>1.967441</td>
      <td>00:32</td>
    </tr>
    <tr>
      <td>1</td>
      <td>1.727627</td>
      <td>1.706729</td>
      <td>00:31</td>
    </tr>
    <tr>
      <td>2</td>
      <td>1.566641</td>
      <td>1.595630</td>
      <td>00:31</td>
    </tr>
    <tr>
      <td>3</td>
      <td>1.463253</td>
      <td>1.530451</td>
      <td>00:31</td>
    </tr>
    <tr>
      <td>4</td>
      <td>1.398891</td>
      <td>1.483463</td>
      <td>00:32</td>
    </tr>
    <tr>
      <td>5</td>
      <td>1.338582</td>
      <td>1.453968</td>
      <td>00:32</td>
    </tr>
  </tbody>
</table>
</div>
</div>
<p>And, now we have results comparable to fp32!</p>
</section>
<section id="can-we-do-this-in-a-non-manual-way" class="level3">
<h3 class="anchored" data-anchor-id="can-we-do-this-in-a-non-manual-way">Can we do this in a non-manual way?</h3>
<p>Well we start at the maximum possible multiple as the <code>loss_scale</code>. We multiply our gradients by this value. Yes, this value is definitely going to be too big so we need a strategy for decreasing the value now.</p>
<div class="cell">
<div class="sourceCode cell-code" id="cb33"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb33-1"><a href="#cb33-1" aria-hidden="true" tabindex="-1"></a><span class="at">@patch</span></span>
<span id="cb33-2"><a href="#cb33-2" aria-hidden="true" tabindex="-1"></a><span class="kw">def</span> before_fit(<span class="va">self</span>:fp16Callback):</span>
<span id="cb33-3"><a href="#cb33-3" aria-hidden="true" tabindex="-1"></a>    <span class="va">self</span>.loss_scale<span class="op">=</span><span class="fl">2.</span><span class="op">**</span><span class="dv">24</span></span>
<span id="cb33-4"><a href="#cb33-4" aria-hidden="true" tabindex="-1"></a>    <span class="va">self</span>.count<span class="op">=</span><span class="dv">0</span></span>
<span id="cb33-5"><a href="#cb33-5" aria-hidden="true" tabindex="-1"></a>    <span class="va">self</span>.opt_params<span class="op">=</span> [p <span class="cf">for</span> p <span class="kw">in</span> <span class="va">self</span>.model.parameters()]</span>
<span id="cb33-6"><a href="#cb33-6" aria-hidden="true" tabindex="-1"></a>    <span class="kw">def</span> f(m,n):</span>
<span id="cb33-7"><a href="#cb33-7" aria-hidden="true" tabindex="-1"></a>        value<span class="op">=</span><span class="bu">getattr</span>(m,n).data.<span class="bu">float</span>() <span class="cf">if</span> <span class="bu">isinstance</span>(m,nn.BatchNorm2d) <span class="cf">else</span> <span class="bu">getattr</span>(m,n).data.half()</span>
<span id="cb33-8"><a href="#cb33-8" aria-hidden="true" tabindex="-1"></a>        <span class="bu">setattr</span>(m,n,nn.Parameter(value))</span>
<span id="cb33-9"><a href="#cb33-9" aria-hidden="true" tabindex="-1"></a>    apply_p(f,<span class="va">self</span>.learn.model)</span>
<span id="cb33-10"><a href="#cb33-10" aria-hidden="true" tabindex="-1"></a><span class="at">@patch</span></span>
<span id="cb33-11"><a href="#cb33-11" aria-hidden="true" tabindex="-1"></a><span class="kw">def</span> before_backward(<span class="va">self</span>:fp16Callback):</span>
<span id="cb33-12"><a href="#cb33-12" aria-hidden="true" tabindex="-1"></a>    <span class="va">self</span>.learn.loss_grad<span class="op">=</span><span class="va">self</span>.loss_scale<span class="op">*</span><span class="va">self</span>.learn.loss_grad</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</div>
<p>This gets really messy, but we decrease by half if we overflow. We then skip the current batch and go to the next batch. This does mean we will hit a lot of skipped batches in the beginning of training. As our model trains, our gradients will probably get smaller, so we will want to increase our <code>loss_scale</code>. For this example we just test every 500 batches to see if we should increase our <code>loss_scale</code>.</p>
<div class="cell" data-execution_count="36">
<div class="sourceCode cell-code" id="cb34"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb34-1"><a href="#cb34-1" aria-hidden="true" tabindex="-1"></a><span class="at">@patch</span></span>
<span id="cb34-2"><a href="#cb34-2" aria-hidden="true" tabindex="-1"></a><span class="kw">def</span> after_backward(<span class="va">self</span>:fp16Callback):</span>
<span id="cb34-3"><a href="#cb34-3" aria-hidden="true" tabindex="-1"></a>    <span class="cf">for</span> mp <span class="kw">in</span> <span class="va">self</span>.learn.model.parameters():</span>
<span id="cb34-4"><a href="#cb34-4" aria-hidden="true" tabindex="-1"></a>        <span class="cf">if</span> mp.grad <span class="kw">is</span> <span class="kw">not</span> <span class="va">None</span> <span class="kw">and</span> test_overflow(mp.grad.data):</span>
<span id="cb34-5"><a href="#cb34-5" aria-hidden="true" tabindex="-1"></a>            <span class="va">self</span>.learn.model.zero_grad()</span>
<span id="cb34-6"><a href="#cb34-6" aria-hidden="true" tabindex="-1"></a>            <span class="va">self</span>.loss_scale<span class="op">/=</span><span class="dv">2</span></span>
<span id="cb34-7"><a href="#cb34-7" aria-hidden="true" tabindex="-1"></a>            <span class="cf">raise</span> CancelBatchException()</span>
<span id="cb34-8"><a href="#cb34-8" aria-hidden="true" tabindex="-1"></a>    <span class="cf">for</span> mp,op <span class="kw">in</span> <span class="bu">zip</span>(<span class="va">self</span>.learn.model.parameters(),<span class="va">self</span>.opt_params):</span>
<span id="cb34-9"><a href="#cb34-9" aria-hidden="true" tabindex="-1"></a>        op.grad<span class="op">=</span>mp.grad.to(dtype<span class="op">=</span>torch.float32)<span class="op">/</span><span class="va">self</span>.loss_scale</span>
<span id="cb34-10"><a href="#cb34-10" aria-hidden="true" tabindex="-1"></a>    <span class="va">self</span>.count <span class="op">+=</span> <span class="dv">1</span></span>
<span id="cb34-11"><a href="#cb34-11" aria-hidden="true" tabindex="-1"></a>    <span class="cf">if</span> <span class="va">self</span>.count <span class="op">==</span> <span class="dv">500</span>:</span>
<span id="cb34-12"><a href="#cb34-12" aria-hidden="true" tabindex="-1"></a>        <span class="va">self</span>.count <span class="op">=</span> <span class="dv">0</span></span>
<span id="cb34-13"><a href="#cb34-13" aria-hidden="true" tabindex="-1"></a>        <span class="va">self</span>.loss_scale <span class="op">*=</span> <span class="dv">2</span></span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</div>
<div class="cell" data-execution_count="37">
<div class="sourceCode cell-code" id="cb35"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb35-1"><a href="#cb35-1" aria-hidden="true" tabindex="-1"></a><span class="cf">with</span> less_random():</span>
<span id="cb35-2"><a href="#cb35-2" aria-hidden="true" tabindex="-1"></a>    dls<span class="op">=</span>create_dls()</span>
<span id="cb35-3"><a href="#cb35-3" aria-hidden="true" tabindex="-1"></a>    learn<span class="op">=</span>Learner(dls,resnet18(),opt_func<span class="op">=</span>SGD,cbs<span class="op">=</span>[fp16Callback,GradLogCallback])</span>
<span id="cb35-4"><a href="#cb35-4" aria-hidden="true" tabindex="-1"></a>    learn.fit(<span class="dv">6</span>)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-display">

<style>
    /* Turns off some styling */
    progress {
        /* gets rid of default border in Firefox and Opera. */
        border: none;
        /* Needs to be in here for Safari polyfill so background images work as expected. */
        background-size: auto;
    }
    progress:not([value]), progress:not([value])::-webkit-progress-bar {
        background: repeating-linear-gradient(45deg, #7e7e7e, #7e7e7e 10px, #5c5c5c 10px, #5c5c5c 20px);
    }
    .progress-bar-interrupted, .progress-bar-interrupted::-webkit-progress-bar {
        background: #F44336;
    }
</style>
</div>
<div class="cell-output cell-output-display">

<table class="dataframe table table-sm table-striped">
  <thead>
    <tr>
      <th>epoch</th>
      <th>train_loss</th>
      <th>valid_loss</th>
      <th>time</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <td>0</td>
      <td>2.094611</td>
      <td>1.968921</td>
      <td>00:33</td>
    </tr>
    <tr>
      <td>1</td>
      <td>1.729887</td>
      <td>1.698773</td>
      <td>00:33</td>
    </tr>
    <tr>
      <td>2</td>
      <td>1.563014</td>
      <td>1.592412</td>
      <td>00:33</td>
    </tr>
    <tr>
      <td>3</td>
      <td>1.455867</td>
      <td>1.526811</td>
      <td>00:34</td>
    </tr>
    <tr>
      <td>4</td>
      <td>1.397211</td>
      <td>1.486772</td>
      <td>00:34</td>
    </tr>
    <tr>
      <td>5</td>
      <td>1.330738</td>
      <td>1.447847</td>
      <td>00:34</td>
    </tr>
  </tbody>
</table>
</div>
</div>
<p>You can look more into all of this by checking out <code>NonNativeMixedPrecision</code>.</p>


</section>

</main> <!-- /main -->
<script id="quarto-html-after-body" type="application/javascript">
window.document.addEventListener("DOMContentLoaded", function (event) {
  const toggleBodyColorMode = (bsSheetEl) => {
    const mode = bsSheetEl.getAttribute("data-mode");
    const bodyEl = window.document.querySelector("body");
    if (mode === "dark") {
      bodyEl.classList.add("quarto-dark");
      bodyEl.classList.remove("quarto-light");
    } else {
      bodyEl.classList.add("quarto-light");
      bodyEl.classList.remove("quarto-dark");
    }
  }
  const toggleBodyColorPrimary = () => {
    const bsSheetEl = window.document.querySelector("link#quarto-bootstrap");
    if (bsSheetEl) {
      toggleBodyColorMode(bsSheetEl);
    }
  }
  toggleBodyColorPrimary();  
  const icon = "";
  const anchorJS = new window.AnchorJS();
  anchorJS.options = {
    placement: 'right',
    icon: icon
  };
  anchorJS.add('.anchored');
  const clipboard = new window.ClipboardJS('.code-copy-button', {
    target: function(trigger) {
      return trigger.previousElementSibling;
    }
  });
  clipboard.on('success', function(e) {
    // button target
    const button = e.trigger;
    // don't keep focus
    button.blur();
    // flash "checked"
    button.classList.add('code-copy-button-checked');
    var currentTitle = button.getAttribute("title");
    button.setAttribute("title", "Copied!");
    setTimeout(function() {
      button.setAttribute("title", currentTitle);
      button.classList.remove('code-copy-button-checked');
    }, 1000);
    // clear code selection
    e.clearSelection();
  });
  function tippyHover(el, contentFn) {
    const config = {
      allowHTML: true,
      content: contentFn,
      maxWidth: 500,
      delay: 100,
      arrow: false,
      appendTo: function(el) {
          return el.parentElement;
      },
      interactive: true,
      interactiveBorder: 10,
      theme: 'quarto',
      placement: 'bottom-start'
    };
    window.tippy(el, config); 
  }
  const noterefs = window.document.querySelectorAll('a[role="doc-noteref"]');
  for (var i=0; i<noterefs.length; i++) {
    const ref = noterefs[i];
    tippyHover(ref, function() {
      let href = ref.getAttribute('href');
      try { href = new URL(href).hash; } catch {}
      const id = href.replace(/^#\/?/, "");
      const note = window.document.getElementById(id);
      return note.innerHTML;
    });
  }
  var bibliorefs = window.document.querySelectorAll('a[role="doc-biblioref"]');
  for (var i=0; i<bibliorefs.length; i++) {
    const ref = bibliorefs[i];
    const cites = ref.parentNode.getAttribute('data-cites').split(' ');
    tippyHover(ref, function() {
      var popup = window.document.createElement('div');
      cites.forEach(function(cite) {
        var citeDiv = window.document.createElement('div');
        citeDiv.classList.add('hanging-indent');
        citeDiv.classList.add('csl-entry');
        var biblioDiv = window.document.getElementById('ref-' + cite);
        if (biblioDiv) {
          citeDiv.innerHTML = biblioDiv.innerHTML;
        }
        popup.appendChild(citeDiv);
      });
      return popup.innerHTML;
    });
  }
});
</script>
</div> <!-- /content -->



</body></html>