# AUTOGENERATED! DO NOT EDIT! File to edit: ../Refactor.ipynb.

# %% auto 0
__all__ = ['del_if_exists', 'TensorNoise', 'TensorStep', 'decodes', 'ItemTransform', 'DiffusionTuple', 'ToDiffusionTuple',
           'LabelToNoise', 'LinearNoiseSchedule', 'DDPM_Q_Sampling', 'DiffusionSamplingTransform',
           'Diffusion_P_Sampler', 'DDPM_P_Sampling', 'DDIM_P_Sampling', 'show_results', 'show_batch', 'FlattenCallback',
           'mse_loss_weighted', 'snr', 'continuous_weights', 'WeightedLinSched']

# %% ../Refactor.ipynb 2
#| echo: false
from fastai.basics import *
from fastai.vision.models.unet import *
from fastai.vision.all import *
from fastai.torch_basics import *
from denoising_diffusion_pytorch import Unet
from fastai.callback.wandb import _make_plt
from torch import autocast
from fastcore.transform import _is_tuple
from fastai.vision.gan import InvisibleTensor,generate_noise

# %% ../Refactor.ipynb 3
#| echo: false
def del_if_exists(to_del='',delim=','):
    for n in to_del.split(delim): 
        if n in globals(): del globals()[n]

# %% ../Refactor.ipynb 6
class TensorNoise(TensorImageBase):pass
class TensorStep(TensorBase): pass

# %% ../Refactor.ipynb 8
@Normalize
def decodes(self, x:TensorNoise):
    f = to_cpu if x.device.type=='cpu' else noop
    return (x*f(self.std) + f(self.mean))

# %% ../Refactor.ipynb 13
#| echo: false
class ItemTransform(Transform):
    "A transform that always take tuples as items"
    _retain = True
    def __call__(self, x, **kwargs): return self._call1(x, '__call__', **kwargs)
    def decode(self, x, **kwargs):   return self._call1(x, 'decode', **kwargs)
    def _call1(self:ItemTransform, x, name, **kwargs):
        if not _is_tuple(x): return getattr(super(), name)(x, **kwargs)
        y=self._call_tuple(name,x,**kwargs)
        if not self._retain: return y
        if is_listy(y) and not isinstance(y, tuple): y = tuple(y)
        return retain_type(y, x)
    def _call_tuple(self:ItemTransform, name, x, split_idx=None, **kwargs):
        f = getattr(super(), name)
        f2name='encodes' if name == '__call__' else 'decodes' if name == 'decode' else name
        f2 = getattr(self, f2name)
        if isinstance(f2,TypeDispatch) and f2[type(x)] is not None:
            if split_idx!=self.split_idx and self.split_idx is not None: return x
            y = f2(x, **kwargs)
        else:
            y = f(list(x), **kwargs)
        return y

# %% ../Refactor.ipynb 15
class DiffusionTuple(fastuple):
    def __new__(cls, *rest):
        self=super().__new__(cls, *rest)
        self.dict=OrderedDict()
        i=0
        self.dict['x']=self[i]
        if(isinstance(self[i+1],TensorImage)): self.dict['x0']=self[i:=i+1]
        self.dict['t']=self[i:=i+1]
        if(len(self)>i+1): self.dict['y']=self[i:=i+1]
        if(len(self)>i+1): self.dict['pred']=self[i:=i+1]
        if(len(self)>i+1): self.dict['sampled_pred']=self[i:=i+1]
        return self
    def __getattr__(self, name):
        if(name in self.dict): return self.dict[name]
        raise AttributeError("%s object has no attribute %s"%(type(self).__name__,name))

# %% ../Refactor.ipynb 17
#| echo: false
@patch
def _do_show(self:DiffusionTuple,im,show_noise=False):
    return isinstance(im,TensorImage) or (isinstance(im,TensorNoise) and show_noise)
@patch
def show(self:DiffusionTuple, ctx=None, show_noise=False,**kwargs): 
    line = self.x.new_zeros((*self.x.shape[:-1], 10)).long()
    imgs = []
    for im in self[:]: 
        if self._do_show(im,show_noise=show_noise): 
            # must all be of same scale
            if im.dtype.is_floating_point: im=(im* 256).long() 
            imgs+=[line,TensorBase(im.clamp(0, 255))]
    imgs=torch.cat(imgs[1:], dim=self.x.ndim-1)
    if imgs.ndim>3: imgs=imgs[0]
    return show_image( imgs, title=self.t, ctx=ctx, **kwargs)
@patch
def show_each(self:DiffusionTuple, show_noise=False, **kwargs): 
    imgs = {}
    for k,im in self.dict.items(): 
        if self._do_show(im,show_noise=show_noise): 
            # must all be of same scale
            if im.dtype.is_floating_point: im=(im* 256).long() 
            if im.ndim>3: im=im[0]
            im=TensorImage(im.clamp(0, 255))
            fig,ax=plt.subplots(figsize=(4,4))
            if(k=='x'): 
                #plt.close(fig)
                ax = im.show(ax=ax,title=self.t.data)
            else: im.show(ctx=ax)
            plt.close(fig)
            imgs=merge(imgs,{k:fig})
    return imgs

# %% ../Refactor.ipynb 19
class ToDiffusionTuple(ItemTransform):
    order=100
    def encodes(self,xy):
        return DiffusionTuple(*xy[:-1],xy[-1])

# %% ../Refactor.ipynb 21
class LabelToNoise(ItemTransform):
    order=101
    def encodes(self,xy:DiffusionTuple):
        noise=TensorNoise(torch.randn_like(xy.y))
        return DiffusionTuple(xy.dict[k] if k!='y' else noise for k in xy.dict.keys())

# %% ../Refactor.ipynb 32
class LinearNoiseSchedule:
    "Schedule like used in DDPM"
    def __init__(self,betas=None,n_steps=None,device='cuda'):
        if betas is not None: self.n_steps=betas.shape[0]
        if n_steps is None: self.n_steps=1000
        if betas is None: self.betas = torch.linspace(0.0001, 0.02, self.n_steps,device=device)
        self.alphas = 1. - self.betas
        self.alpha_bar = torch.cumprod(self.alphas, dim=0)

# %% ../Refactor.ipynb 36
class DDPM_Q_Sampling():
    def __init__(self,predicts_x=False,noise_schedule=LinearNoiseSchedule(),n_steps=1000,device='cuda'):
        self.device=device
        self.ns=noise_schedule
        self.n_steps=n_steps
        self.t_sched=torch.linspace(0,len(self.ns.alpha_bar)-1,n_steps,dtype=torch.long)[...,None,None,None]
    def __call__(self,x,es,t):
        t=self.t_sched[t]
        a=self.ns.alpha_bar[t].to(device=x.device)
        signal = (a ** .5)*x
        noise = (1-a)**.5 * es
        return signal + noise
    def undo(self,z,es,t):
        "Goes back to the original image given noise. Only works if es is the original noise. If es is a TensorImage, assumes it is the original."
        if(isinstance(es,TensorImage)): 
            return es 
        t=self.t_sched[t]
        a=TensorBase(self.ns.alpha_bar[t].to(device=z.device))
        noise=TensorBase((1-a)**.5 * es)
        return TensorImage((z-noise)/(a ** .5))

# %% ../Refactor.ipynb 37
#| echo: false
class DiffusionSamplingTransform(ItemTransform):
    order=101
    "noise_sampler, or q_sampler, goes to noise at t=T. image sampler, p_sampler, goes to image at t=0"
    def __init__(self,noise_sampler,image_sampler):
        self.q_sample=noise_sampler
        self.p_sample=image_sampler
    def encodes(self,xy:DiffusionTuple):
        xy.q_sample=self.q_sample
        xy.p_sample=self.p_sample
        y=xy.y
        ts = xy.t[:,0]
        noise=TensorBase(xy.y) if(isinstance(xy.y,TensorNoise)) else TensorBase(torch.randn_like(xy.y))
        x=self.q_sample(xy.x, noise,TensorBase(ts),)
        xy.x[:]=x[:]
        return xy
    def decodes(self,xy:DiffusionTuple):
        ts = type(xy.x)(xy.t)
        sampled_y = TensorImage(self.p_sample(xy.x.clone().detach().cuda(),xy.t.clone().detach().cuda()))
        x0 = TensorImage(self.q_sample.undo(xy.x.clone().detach().cuda(),xy.y.clone().detach().cuda(),xy.t[:,0].clone().detach().cuda()))
        return DiffusionTuple(xy.x,x0,*xy[1:],sampled_y)

# %% ../Refactor.ipynb 47
class Diffusion_P_Sampler():
    def __init__(self,model,sampling_function):
        self.device=sampling_function.device
        self.model=model
        self.sampling_function=sampling_function
    # __call__ implemented, but not shown.
    def iter_noise(self,x_t,ts,t_start):
        i=0
        while((ts>0).any()):
            x,t=x_t[ts>0],ts[ts>0]
            with autocast(device_type=self.device, dtype=x.dtype):
                with torch.no_grad(): 
                    e = self.model(x,self.deconvert(t) if i!=0 else t_start)
                x_t[ts>0]=self.sampling_function(x,e,t,t=t_start if i==0 else None)
            ts[ts>0]-=1
            i+=1
            yield x_t

# %% ../Refactor.ipynb 48
#| echo: false
@patch
def __call__(self:Diffusion_P_Sampler,x,ts=None):
    if ts is None: ts=(self.sampling_function.ns.n_steps-1)*torch.ones([x.shape[0],1],device=x.device,dtype=torch.long)
    t_start=TensorBase(ts.flatten())
    ts = self.sampling_function.convert(t_start)
    for xt in self.iter_noise(x,ts,t_start): x=xt
    return x
@patch
def convert(self:Diffusion_P_Sampler,ns_t): return self.sampling_function.convert(ns_t)
@patch
def deconvert(self:Diffusion_P_Sampler,ns_t): return self.sampling_function.deconvert(ns_t)

# %% ../Refactor.ipynb 49
#| echo: false
class DDPM_P_Sampling():
    def __init__(self,predicts_x=False,noise_schedule=LinearNoiseSchedule(),n_steps=1000,device='cuda'):
        self.device=device
        self.ns=noise_schedule
        self.n_steps=n_steps
        self.t_sched=torch.linspace(0,len(self.ns.alpha_bar)-1,n_steps,dtype=torch.long)[...,None,None,None]
        if(predicts_x): raise NotImplementedError()
    def convert(self,ns_t): return ns_t
    def deconvert(self,ns_t): return self.t_sched[ns_t].to(device=ns_t.device).flatten()

# %% ../Refactor.ipynb 51
@patch
def __call__(self:DDPM_P_Sampling,x,es,ns_t,t=None):
    t= self.t_sched[ns_t] if(t is None) else t[...,None,None,None]
    n=torch.randn_like(x)
    e,a,b=self._noise_at_t(es,t),self.ns.alphas[t],self.ns.betas[t]
    signal = (x - e) / (a ** 0.5)
    noise = b**.5 * n
    return signal + noise
@patch
def _noise_at_t(self:DDPM_P_Sampling,es,t):
    eps_coef = (1 - self.ns.alphas[t]) / (1 - self.ns.alpha_bar[t]) ** .5 
    return eps_coef* es

# %% ../Refactor.ipynb 53
#| echo: false
class DDIM_P_Sampling():
    def __init__(self,n_steps=50,noise_schedule=LinearNoiseSchedule(),device='cuda'):
        self.device=device
        self.ns=noise_schedule
        self.n_steps=n_steps
        self.t_sched=torch.linspace(0,self.ns.n_steps-1,n_steps,dtype=torch.long)
    def convert(self,ns_t): return ns_t*(self.n_steps-1)//self.ns.n_steps+1
    def deconvert(self,ns_t): return self.t_sched[ns_t].to(device=ns_t.device)

# %% ../Refactor.ipynb 54
@patch
def __call__(self:DDIM_P_Sampling,z,es,ns_t,t=None):
    if(t is None): t=self.t_sched[ns_t]
    tp1=self.t_sched[ns_t-1]
    a,a_tp1=self.ns.alpha_bar[t][...,None,None,None],self.ns.alpha_bar[tp1][...,None,None,None]
    if isinstance(es,TensorImage): 
        xs=es
        es=(z - (a)**.5 * xs)/(1-a)**.5
    else: xs=(z - (1-a)**.5 * es)/ (a ** .5)
    signal = a_tp1**.5*(xs) 
    noise = (1-a_tp1)**.5*es
    return signal + noise

# %% ../Refactor.ipynb 55
#| echo: false
@typedispatch
def show_results(x:DiffusionTuple, y, samples, outs, ctxs=None, max_n=10, figsize=None,show_noise=False,**kwargs):
    title=DiffusionTuple(*[ x_ for x_ in x[:-1]],*[y_ for y_ in y[-2:]])
    title=[k for k in list(title.dict.keys()) if show_noise or not isinstance(title.dict[k],TensorNoise)]
    title='/'.join(title)
    if ctxs is None: ctxs = get_grid(min(len(x[0]), max_n), ncols=4, figsize=figsize, title=title)
    for i,ctx in enumerate(ctxs): 
        DiffusionTuple(*[ x_[i] for x_ in x[:-1]],*[y_[i] for y_ in y[-2:]]
                      ).show(ctx=ctx,show_noise=show_noise,**kwargs)
    return ctxs
@typedispatch
def show_batch(x:DiffusionTuple, y, samples, ctxs=None, max_n=6, nrows=None, ncols=2, figsize=None,show_noise=False, **kwargs):
    title='/'.join(k for k in x.dict.keys() if show_noise or not isinstance(x.dict[k],TensorNoise))
    if ctxs is None: ctxs = get_grid(3*min(len(x[0]), max_n), nrows=nrows, ncols=3, figsize=figsize, title=title)
    for i,ctx in enumerate(ctxs): DiffusionTuple(*[ x_[i] for x_ in x]).show(show_noise=show_noise,ctx=ctx)

# %% ../Refactor.ipynb 60
#| echo: false
class FlattenCallback(Callback):
    order=1 #after GatherPredsCallback
    def before_batch(self):
        self.xbo=self.xb
        self.learn.xb=(self.xb[0],self.xb[-1].view(self.xb[-1].shape[::2]),)
    def after_batch(self):
        self.learn.xb=self.xbo

# %% ../Refactor.ipynb 62
def mse_loss_weighted(ys,targ):
    return torch.mean(targ.w_sched[...,None] * ((ys - targ).flatten(start_dim=1) ** 2))

# %% ../Refactor.ipynb 63
#| echo: true
def snr(at): return at/(1-at)

# %% ../Refactor.ipynb 65
def continuous_weights(at):
    weights = -snr(at[1:])/(snr(at[1:])-snr(at[:-1]))
    return torch.cat((weights[0:1],weights))

# %% ../Refactor.ipynb 68
class WeightedLinSched(Callback):
    def after_pred(self):
        if(not hasattr(self,'ws')):
            self.ws = continuous_weights(LinearNoiseSchedule().alpha_bar).clip(min=1)
            self.ws /= self.ws.mean()
        ts=self.learn.xb[1].flatten()
        self.learn.yb[0].w_sched=self.ws[ts]
